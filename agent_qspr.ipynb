{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ca916a",
   "metadata": {},
   "source": [
    "# QSPRpred API Integration with LangChain Agent\n",
    "\n",
    "This notebook demonstrates the integration of the BridgeDB API with a LangChain-powered AI agent for biological identifier mapping.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup and Imports\n",
    "2. Papyrus API Wrapper\n",
    "3. Custom LangChain Tool\n",
    "4. AI Agent Configuration\n",
    "5. Testing the Agent\n",
    "6. Additional Utility Functions\n",
    "7. Direct API Calls\n",
    "\n",
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's set up our environment and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5efaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools import BaseTool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from qsprpred.data.sources.papyrus import Papyrus\n",
    "import qsprpred\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API Key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OpenAI API Key is not set. Please check your .env file.\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "dataset_name = \"PapyrusTutorialDataset\"  # name of the file to be generated\n",
    "papyrus_version = \"latest\"  # Papyrus database version\n",
    "data_dir = \"papyrus\"  # directory to store the Papyrus data\n",
    "output_dir = \"data\"  # directory to store the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb660bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from papyrus_scripts.download import download_papyrus\n",
    "# download_papyrus(version='latest', structures=True, descriptors=['mold2', 'unirep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bc71fa",
   "metadata": {},
   "source": [
    "### Practice dataset\n",
    "\n",
    "First we'll create a test dataset for validating the results for the dataset retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52f173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188ad408c62a4ff8b6f87d29a1ca59ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3785"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qsprpred.data.sources.papyrus import Papyrus\n",
    "import qsprpred\n",
    "\n",
    "acc_keys = [\"P29274\"]\n",
    "dataset_name = \"PapyrusTutorialDataset\"  # name of the file to be generated\n",
    "quality = \"high\"  # choose minimum quality from {\"high\", \"medium\", \"low\"}\n",
    "papyrus_version = \"latest\"  # Papyrus database version\n",
    "data_dir = \"papyrus\"  # directory to store the Papyrus data\n",
    "output_dir = \"data\"  # directory to store the generated dataset\n",
    "\n",
    "# Create a Papyrus object, which specifies the version and directory to store the payrus data\n",
    "papyrus = Papyrus(\n",
    "    data_dir=data_dir,\n",
    "    version=papyrus_version,\n",
    "    stereo=False,\n",
    "    plus_only=True,\n",
    ")\n",
    "\n",
    "# Create subset of payrus data for the given accession keys, returns a MoleculeTable\n",
    "mt = papyrus.getData(\n",
    "    dataset_name,\n",
    "    acc_keys,\n",
    "    quality,\n",
    "    output_dir=output_dir,\n",
    "    use_existing=False,\n",
    "    activity_types=[\"Ki\", \"IC50\", \"Kd\"]\n",
    ")\n",
    "mt.getDF().head()\n",
    "\n",
    "len(mt.getDF())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a8bcf",
   "metadata": {},
   "source": [
    "## 2. QSPRpred API Wrapper\n",
    "\n",
    "We'll create a wrapper class for the QSPRpred API to handle identifier mapping requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0bda33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PapyrusAPI Class\n",
    "# This class encapsulates the functionality to interact with the Papyrus database:\n",
    "\n",
    "class PapyrusAPI:\n",
    "    papyrus_version = \"latest\"  # Papyrus database version\n",
    "    data_dir = \"papyrus\"  # directory to store the Papyrus data\n",
    "    output_dir = \"data\"  # directory to store the generated dataset\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_data(acc_keys, quality):\n",
    "        papyrus = Papyrus(\n",
    "                data_dir=data_dir,\n",
    "                version=papyrus_version,\n",
    "                stereo=False,\n",
    "                plus_only=True,\n",
    "            )\n",
    "        # create subset\n",
    "        mt = papyrus.getData(\n",
    "                dataset_name,\n",
    "                acc_keys,\n",
    "                quality,\n",
    "                output_dir=output_dir,\n",
    "                use_existing=False,\n",
    "                activity_types=[\"Ki\", \"IC50\", \"Kd\"]\n",
    "            )\n",
    "        if type(mt) is qsprpred.data.tables.mol.MoleculeTable:\n",
    "            return mt\n",
    "        else:\n",
    "             f\"Error: fetched data is {type(mt)}, should be MoleculeTable \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9c459",
   "metadata": {},
   "source": [
    "## 3. Custom LangChain Tool\n",
    "\n",
    "Now, let's create a custom LangChain tool that uses our BridgeDbAPI wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581d8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.data import QSPRDataset, RandomSplit\n",
    "from qsprpred.data.descriptors.fingerprints import MorganFP\n",
    "from qsprpred.models import SklearnModel, SklearnMetrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from rdkit import Chem\n",
    "\n",
    "# define papyrus dataset handler   \n",
    "\n",
    "class PapyrusDatasetThresholdTool(BaseTool):\n",
    "    name: str =\"dataset_threshold\"\n",
    "    description: str = \"Used for determining if length of Papyrus dataset is higher than threshold\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        # Parse the query; now expecting only four parts: acc_keys, quality, threshold, smiles\n",
    "        parts = query.split(\",\")\n",
    "        if len(parts) != 4:\n",
    "            return \"Error: Query should be in the format 'acc_keys, quality, threshold, smiles\"\n",
    "        acc_keys, quality, threshold, smiles = [p.strip() for p in parts]\n",
    "        \n",
    "        if not Chem.MolFromSmiles(smiles):\n",
    "            return f\"Invalid SMILES found: {smiles}\"\n",
    "        # Attempt to determine if number of rows is higher than threshold\n",
    "        try:\n",
    "            papyrus_set = PapyrusAPI().fetch_data(acc_keys, quality)\n",
    "            num_rows = len(papyrus_set)\n",
    "            # return if number of rows is higher than threshold\n",
    "            if num_rows > float(threshold):\n",
    "                # calculate compound features and split dataset into train and test\n",
    "\n",
    "                dataset = QSPRDataset.fromMolTable(\n",
    "                    papyrus_set,\n",
    "                    name=\"AssessmentTutorialDataset\",\n",
    "                    target_props=[{\"name\": \"pchembl_value_Mean\", \"task\": \"REGRESSION\"}],\n",
    "                    random_state=42\n",
    "                )\n",
    "\n",
    "                dataset.prepareDataset(\n",
    "                    split=RandomSplit(test_fraction=0.2, dataset=papyrus_set),\n",
    "                    feature_calculators=[MorganFP(radius=3, nBits=2048)],\n",
    "                    recalculate_features=True,\n",
    "                )\n",
    "                \n",
    "                # Initialize random forest it with the SklearnModel class\n",
    "                model = SklearnModel(\n",
    "                    base_dir=\"models\",\n",
    "                    alg=RandomForestRegressor,\n",
    "                    name=\"AgentTestModel\",\n",
    "                )\n",
    "\n",
    "                # Finally, we need to fit the model on the complete dataset if we want to use it further\n",
    "                model.fitDataset(dataset)\n",
    "\n",
    "                # predict the potency of compound based on SMILES\n",
    "                predictions = model.predictMols([smiles])\n",
    "                return predictions\n",
    "            # print(result.getDF().Quality.value_counts())\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def _arun(self, query: str) -> str:\n",
    "        # Async implementation (not needed for this tool)\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "    \n",
    "tools = [PapyrusDatasetThresholdTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74786418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e6fc0947e544efa792da073f11fda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[6.26884]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with a different ENSG identifier (e.g., BRCA2)\n",
    "tool = PapyrusDatasetThresholdTool()\n",
    "tool._run(\"P29275, high, 1000, CCCCCC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959af25",
   "metadata": {},
   "source": [
    "## 4. AI Agent Configuration\n",
    "\n",
    "Let's set up our AI agent using the custom tool we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98758651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: If the number of rows is higher than 1000 for papyrus_set with acc key P29275 and quality high, predict the potency of a compound with smiles CCCCCC\n",
      "\n",
      "----\n",
      "----\n",
      "----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08e9c4878854647820681f0b977f35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "The number of rows in the Papyrus dataset for the specified conditions (acc key P29275 and quality high) is higher than 1000. \n",
      "\n",
      "Now, I will proceed to predict the potency of the compound with the SMILES representation \"CCCCCC\".\n",
      "----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5763df4762cb4dc8af46fc9ad1e108a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "The predicted potency of the compound with the SMILES representation \"CCCCCC\" is approximately 6.23.\n",
      "----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def create_bridgedb_agent():\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    tools = [PapyrusDatasetThresholdTool()]\n",
    "    memory = MemorySaver()\n",
    "    agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "    return agent_executor\n",
    "\n",
    "papyrus_agent = create_bridgedb_agent()\n",
    "\n",
    "def run_agent_query(query):\n",
    "    config = {\"configurable\": {\"thread_id\": \"qspr_conversation\"}}\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    for chunk in papyrus_agent.stream(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        config\n",
    "    ):\n",
    "        if 'agent' in chunk and 'messages' in chunk['agent']:\n",
    "            for message in chunk['agent']['messages']:\n",
    "                if hasattr(message, 'content') and message.content:\n",
    "                    print(message.content)\n",
    "        print(\"----\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Test queries\n",
    "\n",
    "run_agent_query(\"If the number of rows is higher than 1000 for papyrus_set with acc key P29275 and quality high, predict the potency of a compound with smiles CCCCCC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
